{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvhbkVagJ7v0yvnc8a1Kh/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/footing11/custom-MLP-for-fashion-mnist-dataset/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9fGxLVDCiAsb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a GPU is available; otherwise, use the CPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "0PyEz1gKJ3v6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to transform the images into tensors and normalize them.\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize pixel values to range [-1, 1]\n",
        "])"
      ],
      "metadata": {
        "id": "D_Vyc4yNKEoW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the training and test datasets\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dONSnuT2KOW5",
        "outputId": "c0b40a6f-455a-4836-a5d6-7d463e931a99"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:03<00:00, 6.95MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 133kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:08<00:00, 518kB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 4.80MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders for training and testing\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "d0Kv6TzkKWxx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model define\n",
        "# This is a simple MLP with one hidden layer.\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 256)  # First layer (input to hidden)\n",
        "        self.fc2 = nn.Linear(256, 128)    # Second hidden layer\n",
        "        self.fc3 = nn.Linear(128, 10)     # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)  # Flatten the input image\n",
        "        x = torch.relu(self.fc1(x))  # Apply ReLU activation\n",
        "        x = torch.relu(self.fc2(x))  # Apply ReLU activation\n",
        "        x = self.fc3(x)              # Output without activation (raw scores)\n",
        "        return x"
      ],
      "metadata": {
        "id": "vYw1W5-tKd6u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Loss Function and Optimizer\n",
        "model = MLP().to(device)\n",
        "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n"
      ],
      "metadata": {
        "id": "N8pP22EYKsjG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "epochs = 10  # Number of epochs for training\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()  # Clear gradients for this step\n",
        "        outputs = model(images)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Calculate loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update weights\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNWA0BS8K_gb",
        "outputId": "d93d5dec-6666-4f10-b320-6e894b5d07ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4963\n",
            "Epoch [2/10], Loss: 0.3692\n",
            "Epoch [3/10], Loss: 0.3273\n",
            "Epoch [4/10], Loss: 0.3060\n",
            "Epoch [5/10], Loss: 0.2842\n",
            "Epoch [6/10], Loss: 0.2689\n",
            "Epoch [7/10], Loss: 0.2544\n",
            "Epoch [8/10], Loss: 0.2430\n",
            "Epoch [9/10], Loss: 0.2323\n",
            "Epoch [10/10], Loss: 0.2204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model evaluation on test data\n",
        "model.eval()\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "total = len(test_dataset)\n",
        "accuracy = (correct / total) * 100\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5P6HPJlLOU7",
        "outputId": "d732b810-97f1-49ab-89cc-5e120d13f274"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 87.63%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model weights using PyTorch's `torch.save` function.\n",
        "torch.save(model.state_dict(), 'mlp_fashion_mnist_weights.pth')\n",
        "print(\"Model weights saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8akade_LjE4",
        "outputId": "b8a54136-a48a-49dc-be04-37203e7279a8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define basic ReLU and softmax functions manually.\n",
        "def relu(x):\n",
        "    return torch.maximum(torch.zeros_like(x), x)\n",
        "\n",
        "def softmax(x):\n",
        "    exp_x = torch.exp(x - torch.max(x))  # Subtract max for numerical stability\n",
        "    return exp_x / exp_x.sum(dim=1, keepdim=True)"
      ],
      "metadata": {
        "id": "wd5Bua7WLsHm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load weights into a custom MLP structure without high-level functions\n",
        "custom_weights = torch.load('mlp_fashion_mnist_weights.pth', map_location='cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUyB6_GmMEnU",
        "outputId": "3e5eb265-b4dc-4314-f602-af9ceabe6179"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-a795bf46d1ce>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  custom_weights = torch.load('mlp_fashion_mnist_weights.pth', map_location='cpu')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom inference function using basic operations\n",
        "def custom_inference(x):\n",
        "    x = x.view(-1, 28*28)\n",
        "    x = torch.matmul(x, custom_weights['fc1.weight'].T) + custom_weights['fc1.bias']\n",
        "    x = relu(x)\n",
        "    x = torch.matmul(x, custom_weights['fc2.weight'].T) + custom_weights['fc2.bias']\n",
        "    x = relu(x)\n",
        "    x = torch.matmul(x, custom_weights['fc3.weight'].T) + custom_weights['fc3.bias']\n",
        "    x = softmax(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "y7FaH4OUMOTs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing Outputs from Both Models\n",
        "# Use two random samples from the test set\n",
        "import random\n",
        "model.eval()\n",
        "for i in range(2):\n",
        "    index = random.randint(0, len(test_dataset) - 1)\n",
        "    image, label = test_dataset[index]\n",
        "    image = image.unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Get outputs from the PyTorch model\n",
        "    image = image.to('cpu')\n",
        "    output_pytorch = model(image).detach()\n",
        "    output_custom = custom_inference(image)\n",
        "\n",
        "    print(f\"Sample {i+1}:\")\n",
        "    print(f\"True Label: {label}\")\n",
        "    print(f\"PyTorch Model Output: {output_pytorch}\")\n",
        "    print(f\"Custom Model Output: {output_custom}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFc49DRcMU7a",
        "outputId": "7e617273-5d71-4ed4-8e84-1af904e62a60"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1:\n",
            "True Label: 2\n",
            "PyTorch Model Output: tensor([[ 0.9657, -7.1727,  4.4428, -3.4468, -0.1081, -6.8258, -0.3674, -9.2312,\n",
            "         -7.3935, -4.9447]])\n",
            "Custom Model Output: tensor([[2.9423e-02, 8.5946e-06, 9.5230e-01, 3.5675e-04, 1.0054e-02, 1.2159e-05,\n",
            "         7.7575e-03, 1.0970e-06, 6.8916e-06, 7.9767e-05]])\n",
            "Sample 2:\n",
            "True Label: 6\n",
            "PyTorch Model Output: tensor([[ -1.5064, -13.0206,   4.5136,  -3.9776,  -0.3133,  -9.5238,   5.2332,\n",
            "          -9.3489,  -5.2601,  -8.6978]])\n",
            "Custom Model Output: tensor([[7.9296e-04, 7.9189e-09, 3.2633e-01, 6.6989e-05, 2.6144e-03, 2.6139e-07,\n",
            "         6.7017e-01, 3.1136e-07, 1.8579e-05, 5.9707e-07]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the Number of Parameters\n",
        "# Cstom function to count the parameters of the model\n",
        "def count_parameters(model):\n",
        "    total_params = 0\n",
        "    layer_params = {}\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            param_count = param.numel()\n",
        "            total_params += param_count\n",
        "            layer_params[name] = param_count\n",
        "    return total_params, layer_params"
      ],
      "metadata": {
        "id": "BLp8aOPUModu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of parameters\n",
        "total_params, layer_params = count_parameters(model)\n",
        "print(f\"Total Parameters: {total_params}\")\n",
        "print(f\"Parameters by Layer: {layer_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQVNpTLJMwQw",
        "outputId": "10934351-6a51-4292-de0b-f97bd9f64dc3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Parameters: 235146\n",
            "Parameters by Layer: {'fc1.weight': 200704, 'fc1.bias': 256, 'fc2.weight': 32768, 'fc2.bias': 128, 'fc3.weight': 1280, 'fc3.bias': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run inference on CPU and GPU and Compare Execution Times\n",
        "image, _ = test_dataset[random.randint(0, len(test_dataset) - 1)]\n",
        "image = image.unsqueeze(0).to(device)"
      ],
      "metadata": {
        "id": "SfMElSPzM0o2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "output_cpu = model(image.to('cpu')).detach()\n",
        "cpu_time = time.time() - start_time"
      ],
      "metadata": {
        "id": "DMk3XBEKM9ks"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "output_gpu = model(image.to('cuda' if torch.cuda.is_available() else 'cpu')).detach()\n",
        "gpu_time = time.time() - start_time"
      ],
      "metadata": {
        "id": "h4UqdPjaNLMw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"CPU Inference Time: {cpu_time:.6f} seconds\")\n",
        "print(f\"GPU Inference Time: {gpu_time:.6f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BtkgNr-NQay",
        "outputId": "8c8fa7f9-af29-43ab-e721-9e252db30171"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Inference Time: 0.002114 seconds\n",
            "GPU Inference Time: 0.002129 seconds\n"
          ]
        }
      ]
    }
  ]
}